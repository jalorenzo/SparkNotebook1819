{
  "paragraphs": [
    {
      "text": "%md\nIntroduction to [Apache Spark](http://spark.apache.org/)\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d",
      "user": "anonymous",
      "dateUpdated": "2018-10-05 08:17:13.253",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12.0,
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eIntroduction to \u003ca href\u003d\"http://spark.apache.org/\"\u003eApache Spark\u003c/a\u003e\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508243612734_42507456",
      "id": "20170329-135315_716642539",
      "dateCreated": "2017-10-17 12:33:32.000",
      "dateStarted": "2018-10-05 08:17:11.628",
      "dateFinished": "2018-10-05 08:17:11.667",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### A fast cluster computing platform\n\n-   It extends the MapReduce model to support efficiently other computing types\n\n    -   Interactive queries\n\n    -   Streaming processing\n\n-   Supports in-memory computations\n\n-   Surpasses MapReduce for complex operations (10-20x faster)\n\n#### Gereral-purpose\n\n-   Batch, interactive or streaming processing modes\n\n-   Reduces the number of tools to use and maintain",
      "user": "anonymous",
      "dateUpdated": "2018-10-05 08:17:19.283",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 6.0,
        "editorHide": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 346.0,
              "optionOpen": false
            }
          }
        },
        "enabled": false,
        "fontSize": 9.0,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eA fast cluster computing platform\u003c/h3\u003e\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eIt extends the MapReduce model to support efficiently other computing types\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003e\n      \u003cp\u003eInteractive queries\u003c/p\u003e\u003c/li\u003e\n      \u003cli\u003e\n      \u003cp\u003eStreaming processing\u003c/p\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eSupports in-memory computations\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eSurpasses MapReduce for complex operations (10-20x faster)\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eGereral-purpose\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003e\n  \u003cp\u003eBatch, interactive or streaming processing modes\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eReduces the number of tools to use and maintain\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508243612752_34042980",
      "id": "20170329-135340_1848752981",
      "dateCreated": "2017-10-17 12:33:32.000",
      "dateStarted": "2018-10-05 08:17:17.806",
      "dateFinished": "2018-10-05 08:17:17.903",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### History\n\n-   Started in 2009 in the UC Berkeley RAD Lab (AMPLab)\n\n    -   Motivated by MapReduce\u0027s lack of efficiency for iterative and interactive jobs\n\n-   Main contributors: [Databricks](https://databricks.com/), Yahoo! and Intel\n\n-   Licensed as an open source project in March 2010\n\n-   Transferred to the Apache Software Foundation in June 2013, Top Level Project in February 2014\n\n-   One of the most active Big Data projects\n\n-   Version 1.0 launched in May 2014",
      "user": "anonymous",
      "dateUpdated": "2018-08-10 11:53:16.653",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 6.0,
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eHistory\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eStarted in 2009 in the UC Berkeley RAD Lab (AMPLab)\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003e\n      \u003cp\u003eMotivated by MapReduce\u0026rsquo;s lack of efficiency for iterative and interactive jobs\u003c/p\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eMain contributors: \u003ca href\u003d\"https://databricks.com/\"\u003eDatabricks\u003c/a\u003e, Yahoo! and Intel\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eLicensed as an open source project in March 2010\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eTransferred to the Apache Software Foundation in June 2013, Top Level Project in February 2014\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eOne of the most active Big Data projects\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eVersion 1.0 launched in May 2014\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508243612752_34042980",
      "id": "20170329-135351_1564714588",
      "dateCreated": "2017-10-17 12:33:32.000",
      "dateStarted": "2018-08-10 11:53:12.961",
      "dateFinished": "2018-08-10 11:53:13.043",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Spark features\n\n- It supports a variety of workloads: batch, interactive queries, streaming, machine learning, graph processing...\n- APIs in Scala, Java, Python, SQL and R\n- Interactive shells in Scala and Python\n- Integrates smoothly with other Big Data solutions like HDFS, Cassandra, etc.",
      "user": "anonymous",
      "dateUpdated": "2018-10-05 08:08:45.102",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eSpark features\u003c/h3\u003e\n\u003cul\u003e\n  \u003cli\u003eIt supports a variety of workloads: batch, interactive queries, streaming, machine learning, graph processing\u0026hellip;\u003c/li\u003e\n  \u003cli\u003eAPIs in Scala, Java, Python, SQL and R\u003c/li\u003e\n  \u003cli\u003eInteractive shells in Scala and Python\u003c/li\u003e\n  \u003cli\u003eIntegrates smoothly with other Big Data solutions like HDFS, Cassandra, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538726808879_1113067544",
      "id": "20181005-080648_1807589426",
      "dateCreated": "2018-10-05 08:06:48.880",
      "dateStarted": "2018-10-05 08:08:33.583",
      "dateFinished": "2018-10-05 08:08:33.653",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### The Spark stack\n\u003chr /\u003e\n![sparkstack](http://localhost:8080/assets/images/sparkstack.png)\n(Source: H. Karau, A. Konwinski, P. Wendell, M. Zaharia, \"Learning Spark\", O\u0027Reilly, 2015)\n\u003chr /\u003e",
      "user": "anonymous",
      "dateUpdated": "2018-11-02 08:35:08.113",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12.0,
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eThe Spark stack\u003c/h3\u003e\n\u003chr /\u003e\n\u003cp\u003e\u003cimg src\u003d\"http://localhost:8080/assets/images/sparkstack.png\" alt\u003d\"sparkstack\" /\u003e\u003cbr/\u003e(Source: H. Karau, A. Konwinski, P. Wendell, M. Zaharia, \u0026ldquo;Learning Spark\u0026rdquo;, O\u0026rsquo;Reilly, 2015)\u003cbr/\u003e\u003chr /\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508243612753_33658231",
      "id": "20170329-135424_1926415155",
      "dateCreated": "2017-10-17 12:33:32.000",
      "dateStarted": "2018-11-02 08:35:04.211",
      "dateFinished": "2018-11-02 08:35:06.247",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Key concepts\n\u003chr /\u003e\n![sparkcontext](http://localhost:8080/assets/images/sparkcontext.png)\n(Source: H. Karau, A. Konwinski, P. Wendell, M. Zaharia, \"Learning Spark\", O\u0027Reilly, 2015)\n\u003chr /\u003e",
      "user": "anonymous",
      "dateUpdated": "2018-10-30 16:18:52.876",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12.0,
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eKey concepts\u003c/h3\u003e\n\u003chr /\u003e\n\u003cp\u003e\u003cimg src\u003d\"http://localhost:8080/assets/images/sparkcontext.png\" alt\u003d\"sparkcontext\" /\u003e\u003cbr/\u003e(Source: H. Karau, A. Konwinski, P. Wendell, M. Zaharia, \u0026ldquo;Learning Spark\u0026rdquo;, O\u0026rsquo;Reilly, 2015)\u003cbr/\u003e\u003chr /\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508243612754_34812478",
      "id": "20170329-140013_258148990",
      "dateCreated": "2017-10-17 12:33:32.000",
      "dateStarted": "2018-10-30 16:18:48.407",
      "dateFinished": "2018-10-30 16:18:51.539",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Driver\n\n-   It creates a `SparkContext`\n\n-   Turns the user program into a set of tasks:\n\n    -   Logical operations `DAG` -\u003e physical execution plan\n\n-   Schedules the tasks to perform on the executors. \n\n#### SparkContext\n\n-   The SparkContext performs the connection to the cluster\n\n    -   Allows building RDDs from files, lists or other objects\n\n-   In this notebook (or in the Spark shell) it is automatically defined (`sc` variable)\n\n-   Creation on a Python script\n\n        from pyspark import SparkContext\n        sc \u003d SparkContext(master\u003d\"local\", appName\u003d\"My app\")\n",
      "user": "anonymous",
      "dateUpdated": "2018-08-10 11:24:04.171",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 6.0,
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eDriver\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003e\n  \u003cp\u003eIt creates a \u003ccode\u003eSparkContext\u003c/code\u003e\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eTurns the user program into a set of tasks:\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003e\n      \u003cp\u003eLogical operations \u003ccode\u003eDAG\u003c/code\u003e -\u0026gt; physical execution plan\u003c/p\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eSchedules the tasks to perform on the executors. \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eSparkContext\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eThe SparkContext performs the connection to the cluster\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003e\n      \u003cp\u003eAllows building RDDs from files, lists or other objects\u003c/p\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eIn this notebook (or in the Spark shell) it is automatically defined (\u003ccode\u003esc\u003c/code\u003e variable)\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eCreation on a Python script\u003c/p\u003e\n    \u003cpre\u003e\u003ccode\u003efrom pyspark import SparkContext\nsc \u003d SparkContext(master\u003d\u0026quot;local\u0026quot;, appName\u003d\u0026quot;My app\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508243612754_34812478",
      "id": "20170329-141758_1410852644",
      "dateCreated": "2017-10-17 12:33:32.000",
      "dateStarted": "2018-08-10 10:15:58.161",
      "dateFinished": "2018-08-10 10:15:58.259",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n-   Creation on a Scala program\n   \n        import org.apache.spark.SparkContext\n        import org.apache.spark.SparkContext._\n        import org.apache.spark.SparkConf\n        val conf \u003d new SparkConf().setMaster(\"local\").setAppName(\"My App\")\n        val sc \u003d new SparkContext(conf)\n       \n\n#### Executors\n\n-   Execute each individual task and return the results to the Driver\n\n-   Provide a store space in memory for the tasks data\n\n#### Cluster Manager\n\n-   *Pluggable* component on Spark\n\n-   YARN, Mesos or Spark Standalone",
      "user": "anonymous",
      "dateUpdated": "2018-08-10 10:19:04.133",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 6.0,
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003eCreation on a Scala program\n    \u003cpre\u003e\u003ccode\u003eimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkConf\nval conf \u003d new SparkConf().setMaster(\u0026quot;local\u0026quot;).setAppName(\u0026quot;My App\u0026quot;)\nval sc \u003d new SparkContext(conf)\n\u003c/code\u003e\u003c/pre\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eExecutors\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003e\n  \u003cp\u003eExecute each individual task and return the results to the Driver\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eProvide a store space in memory for the tasks data\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eCluster Manager\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003e\n  \u003cp\u003e\u003cem\u003ePluggable\u003c/em\u003e component on Spark\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eYARN, Mesos or Spark Standalone\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508243612754_34812478",
      "id": "20170329-142050_1602884490",
      "dateCreated": "2017-10-17 12:33:32.000",
      "dateStarted": "2018-08-10 10:18:47.315",
      "dateFinished": "2018-08-10 10:18:47.450",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "2017-10-17 12:33:32.000",
      "config": {
        "editorMode": "ace/mode/scala",
        "colWidth": 12.0,
        "results": {},
        "enabled": false,
        "editorSetting": {
          "language": "scala"
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508243612755_34427729",
      "id": "20170329-142126_1062577642",
      "dateCreated": "2017-10-17 12:33:32.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Spark course/01 - Introduction to Apache Spark",
  "id": "2CX6XYA24",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}